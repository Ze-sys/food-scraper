{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data url scraping\n",
    "- using Selenium"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "source": [
    "class grab_urls:\n",
    "    def __init__(self,url):\n",
    "        self.url = url  \n",
    "        self.opts = Options()\n",
    "        self.opts.add_argument(\"--incognito\")\n",
    "        self.opts.headless = True\n",
    "        self.driver = Chrome(options=self.opts)\n",
    "        self.driver.get(self.url)\n",
    "        \n",
    "\n",
    "def url_grabber(driver):\n",
    "    all_links = []\n",
    "    while True:\n",
    "        if 'page=2' in driver.current_url:\n",
    "            try:\n",
    "                linklist = driver.find_elements_by_xpath(\"/html/body/main/div[2]/div/div[*]/div[2]/div/a\")\n",
    "                links = [s.get_attribute('href') for s in linklist] \n",
    "                    \n",
    "            except ElementClickInterceptedException:\n",
    "                popup = driver.find_element_by_xpath(\"/html/body/div[12]/div/div[2]/div[2]/button[1]\")\n",
    "                popup.click()\n",
    "                linklist = driver.find_elements_by_xpath(\"/html/body/main/div[2]/div/div[*]/div[2]/div/a\")\n",
    "                links = [s.get_attribute('href') for s in linklist] \n",
    "            all_links.append(links)\n",
    "\n",
    "            page_lister = driver.find_element_by_class_name(\"category-page-list-related-nav-container\")\n",
    "            if len(page_lister.find_elements_by_tag_name(\"a\"))==2: # 2 buttons(prev,next)\n",
    "                next_page = page_lister.find_elements_by_tag_name(\"a\")[1] #driver.find_element_by_xpath(\"/html/body/main/div[2]/div/div[29]/a[2]\")\n",
    "                next_page.click()\n",
    "            else:\n",
    "                return  all_links\n",
    "                driver.quit()\n",
    "                break\n",
    "\n",
    "\n",
    "        else:\n",
    "            driver.implicitly_wait(45)\n",
    "            linklist = driver.find_elements_by_xpath(\"/html/body/main/div[2]/div/div[*]/div[2]/div/a\")\n",
    "            links = [s.get_attribute('href') for s in linklist]\n",
    "            all_links.append(links)\n",
    "            page_lister = driver.find_element_by_class_name(\"category-page-list-related-nav-container\")\n",
    "            \n",
    "            if len(page_lister.find_elements_by_tag_name(\"a\"))==2: # 2 buttons(prev,next)\n",
    "                next_page = page_lister.find_elements_by_tag_name(\"a\")[1] #driver.find_element_by_xpath(\"/html/body/main/div[2]/div/div[29]/a[2]\")\n",
    "                next_page.click()\n",
    "            else:\n",
    "                driver.quit()\n",
    "                break\n",
    "\n",
    "    return  all_links        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "source": [
    "url_list = [\n",
    "\"https://www.allrecipes.com/recipes/102/appetizers-and-snacks/antipasto/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/14741/meat-and-poultry/pork/bacon/appetizers/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/16833/appetizers-and-snacks/bruschetta/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/17249/appetizers-and-snacks/canapes-and-crostini/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/104/appetizers-and-snacks/cheese/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/1240/appetizers-and-snacks/seafood/crab/crab-cakes/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/16212/appetizers-and-snacks/snacks/crackers/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/110/appetizers-and-snacks/deviled-eggs/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/105/appetizers-and-snacks/dips-and-spreads/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/1281/appetizers-and-snacks/dips-and-spreads/hummus/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/436/appetizers-and-snacks/dips-and-spreads/salsa/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/1244/appetizers-and-snacks/dips-and-spreads/shrimp-dip/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/1242/appetizers-and-snacks/dips-and-spreads/spinach-dips/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/1335/appetizers-and-snacks/dips-and-spreads/bean-dips/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/13362/appetizers-and-snacks/dips-and-spreads/fruit-dip/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/435/appetizers-and-snacks/dips-and-spreads/pate/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/16068/breakfast-and-brunch/pancakes/whole-grain-pancakes/?page=2\"\n",
    "\"https://www.allrecipes.com/recipes/16128/drinks/smoothies/banana/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/16130/drinks/smoothies/blueberry/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/17693/drinks/smoothies/green/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/16131/drinks/smoothies/mango/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/16129/drinks/smoothies/orange/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/16127/drinks/smoothies/strawberry/?page=2\",\n",
    "\"https://www.allrecipes.com/recipes/17578/drinks/smoothies/veggie/?page=2\"\n",
    "]\n",
    "\n",
    "menu_names=[\n",
    "\"appetizers-and-snacks-file\",\n",
    "\"breakfast-and-brunch-file\",\n",
    "\"smoothies-file\"\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "k0,k1,k2=0,0,0\n",
    "for uri in url_list:\n",
    "    if \"appetizers-and-snacks\" in uri:\n",
    "        menu_name = f'{menu_names[0]}-{k0}'\n",
    "        k0 += 1\n",
    "    elif \"breakfast-and-brunch\" in uri:\n",
    "        menu_name = f'{menu_names[1]}-{k1}'\n",
    "        k1 += 1\n",
    "    elif \"smoothies\" in uri:\n",
    "        menu_name = f'{menu_names[2]}-{k2}'\n",
    "        k2 += 1\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    first_url = uri\n",
    "    driver = grab_urls(first_url)\n",
    "    result = url_grabber(driver.driver)\n",
    "    df = pd.DataFrame(result).T\n",
    "    names = [f'page-{i}' for i in range(2,len(result)+2)]\n",
    "    df.columns = names\n",
    "    # df.to_csv('chicken_urls.csv', index=False, header=True)\n",
    "    df.to_csv(f'/home/zelalem/my_repos/mygithubrepos/vacation-projects/recipes/{menu_name}_urls.csv', index=False, header=True, mode = 'a')\n",
    "    \n",
    "t_end = time.time()\n",
    "ellapsed_time = t_end - t_start\n",
    "print('it took', ellapsed_time, 'seconds to scrap just the urls.')    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "it took 51.3529417514801 seconds.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "source": [
    "# Notice scraping has been in headless mode... Still can take a screenshot of the page ( for example to see what's going on when a click is not working) \n",
    "driver.driver.save_screenshot('screenshot99.png')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 255
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "files = [\"appetizers-and-snacks-file-0_urls.csv\",\"appetizers-and-snacks-file-1_urls.csv\" ,\n",
    "\"appetizers-and-snacks-file-2_urls.csv\",\"appetizers-and-snacks-file-3_urls.csv\" ,\n",
    "\"appetizers-and-snacks-file-4_urls.csv\",\"appetizers-and-snacks-file-5_urls.csv\",\n",
    "\"appetizers-and-snacks-file-6_urls.csv\",\"appetizers-and-snacks-file-7_urls.csv\" ,\n",
    "\"breakfast-and-brunch-file-0_urls.csv\",\"smoothies-file-0_urls.csv\" ,\n",
    "\"smoothies-file-1_urls.csv\",\"smoothies-file-2_urls.csv\",\"smoothies-file-3_urls.csv\" ,\n",
    "\"smoothies-file-4_urls.csv\",\"smoothies-file-5_urls.csv\",\"smoothies-file-6_urls.csv\",\n",
    "\"smoothies-file-7_urls.csv\",\"smoothies-file-8_urls.csv\",\n",
    "\"smoothies-file-9_urls.csv\",\"smoothies-file-10_urls.csv\",\"smoothies-file-11_urls.csv\",\n",
    "\"smoothies-file-12_urls.csv\",\"smoothies-file-13_urls.csv\", \"dessert_urls.csv\", \"chicken_urls.csv\"]\n",
    "\n",
    "url_list_all = []\n",
    "for file in files:\n",
    "    # read urls scrapped using Selenium\n",
    "    filename = glob.glob(f'/home/*/*/*/*/recipes/data/{file}')\n",
    "    df = pd.read_csv(filename[0] , sep=\",\", engine='python', skiprows= 0, error_bad_lines=False)\n",
    "    urls = [list(df[name]) for name in df] # make lists out of the df\n",
    "    urls = list(itertools.chain(*urls)) # merge lists\n",
    "    urls = list(filter(None, urls)) # remove NoneType values from list\n",
    "    url_list_all.append(urls)\n",
    "url_list_all = list(itertools.chain(*url_list_all)) # merge lists\n",
    "url_list_all = list(filter(None, url_list_all)) # remove NoneType values from list\n",
    "clean_urls = [x for x in url_list_all if x == x]  # remove nan's\n",
    "\n",
    "print('Total number of urls to scraped using Selenium is {}'.format(len(clean_urls)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of urls to scraped using Selenium is 7464\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# some recipes fall under multiple categories such as smoothies and appetizers - so need to clean duplicates before adding them to the database\n",
    "from iteration_utilities import duplicates\n",
    "print('Total number of duplicate urls is {}'.format(len(list(duplicates(clean_urls)))))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of duplicate urls is 2335\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# removing duplicates\n",
    "clean_urls = list(set(clean_urls))\n",
    "print('Total number of urls to be passed to scrapy is {}'.format(len(clean_urls)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of urls to be passed to scrapy is 5129\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# save urls to csv file- will be read in by spider\n",
    "pd.DataFrame({'urls': clean_urls}).to_csv('/home/zelalem/my_repos/mygithubrepos/vacation-projects/recipes/data/all_recipe_urls.csv', index=False, header=True, mode = 'w')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# read the the csv file for testing\n",
    "filename = glob.glob(f'/home/*/*/*/*/recipes/data/all_recipe_urls.csv')\n",
    "durl = pd.read_csv(filename[0] , sep=\",\", engine='python', skiprows= 0, error_bad_lines=False)\n",
    "durl.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5129 entries, 0 to 5128\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   urls    5129 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 40.2+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "durl.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                     urls\n",
       "count                                                5129\n",
       "unique                                               5129\n",
       "top     https://www.allrecipes.com/recipe/25525/local-...\n",
       "freq                                                    1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://www.allrecipes.com/recipe/25525/local-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "urls_from_df = [list(durl[name]) for name in durl]\n",
    "len(list(itertools.chain(*urls_from_df)))\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5129"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('recipes': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "cd3f906648e255e19ef2b6b0fdce8eb831c38e9e9d6f007127dd7d20a61b9a8f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}